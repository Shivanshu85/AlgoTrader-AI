# Stock Price Prediction - Production Grade Platform

A comprehensive, production-ready machine learning platform for stock price prediction using LSTM and attention mechanisms. Built with enterprise-grade architecture, including data pipelines, model training, serving, monitoring, and deployment infrastructure.

## ğŸ¯ Project Goals

Transform a tutorial LSTM model into a production-grade system with:

- âœ… **Robust Data Engineering**: Multi-source data ingestion with quality validation
- âœ… **Production-grade ML**: Reproducible training, evaluation, and serving
- âœ… **Scalable Architecture**: Kubernetes-ready, cloud-agnostic deployment
- âœ… **Comprehensive Monitoring**: Performance, data quality, and business metrics
- âœ… **Complete Testing**: Unit, integration, and performance tests
- âœ… **Enterprise Security**: Authentication, encryption, audit logging
- âœ… **MLOps Best Practices**: Experiment tracking, model registry, versioning

## ğŸ“‹ Table of Contents

- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Development](#development)
- [Testing](#testing)
- [Deployment](#deployment)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose
- Git
- PostgreSQL 15
- Redis 7

### 1. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/example/stock-predictor-prod.git
cd stock-predictor-prod

# Copy environment file
cp .env.example .env

# Set up development environment (installs dependencies)
make setup

# Start Docker services (PostgreSQL, Redis, MLflow, Airflow)
make docker-up

# Verify all services are running
make health-check
```

### 2. Run Training Pipeline

```bash
# Start a training pipeline
make run-training

# Or use Airflow for scheduling
make run-scheduler
make run-webui  # http://localhost:8080
```

### 3. Start Prediction API

```bash
# Development server (with auto-reload)
make run-api

# Server will be available at http://localhost:8000
# API docs at http://localhost:8000/docs
```

### 4. Monitor Performance

```bash
# Access MLflow tracking UI
open http://localhost:5000

# Monitor with Prometheus/Grafana
open http://localhost:3000  # Username: admin, Password: from .env
```

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Ingestion Layer                         â”‚
â”‚  (Alpha Vantage, IEX Cloud, FMP, Yahoo Finance)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Data Processing Pipeline                       â”‚
â”‚  (Validation, Cleaning, Feature Engineering, Feast)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Model Training & Evaluation                        â”‚
â”‚  (PyTorch LSTM, Attention, Hyperparameter Tuning)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      MLflow Registry                            â”‚
â”‚  (Experiment Tracking, Model Versioning, A/B Testing)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Model Serving & Prediction API                    â”‚
â”‚  (FastAPI, Redis Caching, Load Balancing)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Monitoring, Alerting & Continuous Improvement          â”‚
â”‚  (Prometheus, Grafana, Data Drift Detection)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Orchestration** | Apache Airflow | Workflow scheduling & DAG management |
| **ML Framework** | PyTorch Lightning | Model training & distributed learning |
| **Feature Store** | Feast (upcoming) | Feature management & serving |
| **Model Registry** | MLflow | Experiment tracking & model versioning |
| **API Serving** | FastAPI | REST API for predictions |
| **Caching** | Redis | Feature & prediction caching |
| **Database** | PostgreSQL | Data storage & metadata |
| **Monitoring** | Prometheus + Grafana | Metrics & visualization |
| **Deployment** | Kubernetes | Container orchestration |
| **CI/CD** | GitHub Actions | Automated testing & deployment |

## ğŸ“ Project Structure

```
stock-predictor-prod/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                 # CI/CD pipeline
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                     # Airflow DAGs
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ plugins/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml              # Default configuration
â”‚   â”œâ”€â”€ production.yaml            # Production settings
â”‚   â”œâ”€â”€ prometheus.yml             # Prometheus config
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ provisioning/          # Grafana dashboards
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Original data from APIs
â”‚   â”œâ”€â”€ processed/                 # Cleaned & validated data
â”‚   â””â”€â”€ features/                  # Engineered features
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture/              # System design docs
â”‚   â”‚   â””â”€â”€ adr/                  # Architecture Decision Records
â”‚   â”œâ”€â”€ api/                       # API documentation
â”‚   â””â”€â”€ guides/                    # User guides
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.train           # Training image
â”‚   â”œâ”€â”€ Dockerfile.serve           # Serving image
â”‚   â”œâ”€â”€ Dockerfile.dev             # Development image
â”‚   â””â”€â”€ Dockerfile.airflow         # Airflow image
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml            # K8s deployment
â”‚   â”œâ”€â”€ service.yaml               # K8s service
â”‚   â”œâ”€â”€ configmap.yaml             # K8s config
â”‚   â””â”€â”€ secrets.yaml               # K8s secrets
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration/               # Data exploration
â”‚   â””â”€â”€ experiments/               # Model experiments
â”œâ”€â”€ production/
â”‚   â”œâ”€â”€ data_ingestion/            # Data collection APIs
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ alpha_vantage.py
â”‚   â”‚   â”œâ”€â”€ iex_cloud.py
â”‚   â”‚   â””â”€â”€ validators.py
â”‚   â”œâ”€â”€ features/                  # Feature engineering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ technical_indicators.py
â”‚   â”‚   â”œâ”€â”€ statistical.py
â”‚   â”‚   â””â”€â”€ feature_store.py
â”‚   â”œâ”€â”€ models/                    # Model definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lstm.py
â”‚   â”‚   â”œâ”€â”€ attention.py
â”‚   â”‚   â””â”€â”€ ensemble.py
â”‚   â”œâ”€â”€ training/                  # Training pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py
â”‚   â”‚   â””â”€â”€ callbacks.py
â”‚   â”œâ”€â”€ serving/                   # Prediction serving
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â”œâ”€â”€ models_loader.py
â”‚   â”‚   â””â”€â”€ cache.py
â”‚   â”œâ”€â”€ monitoring/                # Monitoring & metrics
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ data_drift.py
â”‚   â”‚   â””â”€â”€ alerting.py
â”‚   â”œâ”€â”€ utils/                     # Shared utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â””â”€â”€ database.py
â”‚   â””â”€â”€ health_check.py            # System health check
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.sql                # Database initialization
â”‚   â”œâ”€â”€ train_model.py             # Training script
â”‚   â”œâ”€â”€ evaluate_model.py           # Evaluation script
â”‚   â””â”€â”€ deploy_model.py            # Deployment script
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                      # Unit tests
â”‚   â”œâ”€â”€ integration/               # Integration tests
â”‚   â””â”€â”€ performance/               # Performance tests
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml        # Pre-commit hooks
â”œâ”€â”€ docker-compose.yml             # Docker services
â”œâ”€â”€ Makefile                       # Development tasks
â”œâ”€â”€ pyproject.toml                 # Project metadata & dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸ“¦ Installation

### 1. Clone Repository

```bash
git clone https://github.com/example/stock-predictor-prod.git
cd stock-predictor-prod
```

### 2. Set Up Python Environment

**Using venv:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**Using conda:**
```bash
conda create -n stock-pred python=3.10
conda activate stock-pred
```

### 3. Install Dependencies

```bash
# Install pyproject dependencies
pip install -e .

# Install dev dependencies for development
pip install -e ".[dev]"

# Run setup (installs pre-commit hooks)
make setup
```

### 4. Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your API keys and credentials
nano .env
```

### 5. Initialize Database

```bash
# Start PostgreSQL via Docker
make docker-up

# Wait for PostgreSQL to be ready, then initialize
make db-init
```

## ğŸ’» Usage

### Data Ingestion

```python
from production.data_ingestion import AlphaVantageProvider

provider = AlphaVantageProvider(api_key="your_key")
data = provider.get_daily("AAPL", start_date="2023-01-01")
```

### Feature Engineering

```python
from production.features import TechnicalIndicators
from datetime import datetime, timedelta

indicators = TechnicalIndicators(lookback_period=60)
features = indicators.calculate_all(df)
```

### Model Training

```python
from production.training import Trainer
from production.models import LSTMWithAttention

model = LSTMWithAttention(
    input_size=15,  # Number of features
    hidden_size=64,
    num_layers=2,
    dropout=0.2
)

trainer = Trainer(model)
history = trainer.fit(train_loader, val_loader, epochs=50)
```

### Making Predictions

```python
from production.serving import PredictionServer

server = PredictionServer()
prediction = server.predict(
    ticker="AAPL",
    days_ahead=5
)
```

### Via API

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "ticker": "AAPL",
    "days_ahead": 5,
    "confidence_interval": 0.95
  }'
```

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Run only unit tests
make test-unit

# Run integration tests
make test-integration

# Run with coverage report
make test-cov

# Run specific test file
pytest tests/unit/test_feature_engineering.py -v
```

## ğŸ”§ Development

### Code Quality

```bash
# Format code
make format

# Lint code
make lint

# Type checking
make type-check

# Security scanning
make security
```

### Start Development Containers

```bash
# Start all services
make docker-up

# View logs
make docker-logs

# Access services
# PostgreSQL: localhost:5432
# Redis: localhost:6379
# MLflow: http://localhost:5000
# Airflow: http://localhost:8080
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000
# Adminer: http://localhost:8081
```

### Running Jupyter Notebook

```bash
make notebook

# Open http://localhost:8888
```

## ğŸš€ Deployment

### Docker Build

```bash
# Build training image
docker build -f docker/Dockerfile.train -t stock-predictor:latest .

# Build API image
docker build -f docker/Dockerfile.serve -t stock-predictor-api:latest .
```

### Kubernetes Deployment

```bash
# Apply configurations
kubectl apply -f k8s/

# Check deployment status
kubectl get pods
kubectl logs -f <pod-name>
```

### Environment Variables

```bash
# Production deployment requires these environment variables
export POSTGRES_HOST=prod-db.example.com
export POSTGRES_PASSWORD=<secure-password>
export REDIS_HOST=prod-redis.example.com
export MLFLOW_TRACKING_URI=https://mlflow.example.com
export API_KEY_SECRET=<secure-api-key>
```

## ğŸ“Š Monitoring

### MLflow Experiment Tracking

```bash
make run-tracker  # http://localhost:5000
```

### Metrics & Visualization

```bash
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)
```

### Application Logs

```bash
# View logs
docker-compose logs -f api

# Or in development
tail -f logs/app.log
```

## ğŸ“š Documentation

Build and view complete documentation:

```bash
make docs
make docs-serve
```

Navigate to `http://localhost:8000` in your browser.

See the [docs/](docs/) folder for:
- Architecture decisions ([docs/architecture/adr/](docs/architecture/adr/))
- System design ([docs/architecture/system_design.md](docs/architecture/system_design.md))
- API documentation ([docs/api/](docs/api/))
- User guides ([docs/guides/](docs/guides/))

## ğŸ¤ Contributing

1. Create a feature branch (`git checkout -b feature/amazing-feature`)
2. Commit your changes (`git commit -m 'Add amazing feature'`)
3. Push to branch (`git push origin feature/amazing-feature`)
4. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ”— Related Resources

- [PyTorch Documentation](https://pytorch.org/docs)
- [MLflow Documentation](https://mlflow.org/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Airflow Documentation](https://airflow.apache.org/docs)
- [Prometheus Documentation](https://prometheus.io/docs)

## ğŸ“§ Support

For issues, questions, or suggestions:
- Open an [Issue](https://github.com/example/stock-predictor-prod/issues)
- Start a [Discussion](https://github.com/example/stock-predictor-prod/discussions)
- Contact: team@example.com

---

**Built with â¤ï¸ by the ML Engineering Team**
